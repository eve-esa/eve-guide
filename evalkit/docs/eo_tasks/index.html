
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/evalkit/docs/eo_tasks/">
      
      
        <link rel="prev" href="../evalkit/">
      
      
        <link rel="next" href="../examples/">
      
      
        
      
      
      <link rel="icon" href="../../../assets/esa_favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>EO Tasks - EVE GUIDE</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Arial:300,300i,400,400i,700,700i%7CThe+Sans:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Arial";--md-code-font:"The Sans"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#earth-observation-evaluation-tasks" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="EVE GUIDE" class="md-header__button md-logo" aria-label="EVE GUIDE" data-md-component="logo">
      
  <img src="../../../assets/esa_logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            EVE GUIDE
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              EO Tasks
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="EVE GUIDE" class="md-nav__button md-logo" aria-label="EVE GUIDE" data-md-component="logo">
      
  <img src="../../../assets/esa_logo.svg" alt="logo">

    </a>
    EVE GUIDE
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Frontend
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Frontend
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../frontend/docs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../frontend/docs/getting_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Features
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Features
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../frontend/docs/features/chat/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chat
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../frontend/docs/features/control_panel/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Control Panel
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../frontend/docs/features/private_collection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Private Collection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../frontend/docs/features/shared_collection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Shared Collection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../frontend/docs/features/profile/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Profile
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Backend
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Backend
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/getting_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/routers-auth/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Auth
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/routers-collection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Collection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/routers-conversation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Conversation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/routers-document/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Document
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/routers-forgot_password/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Forget Password
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/routers-health_check/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Health Check
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/routers-message/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Message
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/routers-user/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    User
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/types/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Types
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../backend/docs/api/swagger-api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Swagger API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Evalkit
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Evalkit
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evalkit/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evalkit
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    EO Tasks
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    EO Tasks
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-reference" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quick Reference
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#detailed-task-descriptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Detailed Task Descriptions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Detailed Task Descriptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mcqa-multiple-answer" class="md-nav__link">
    <span class="md-ellipsis">
      
        MCQA Multiple Answer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mcqa-single-answer" class="md-nav__link">
    <span class="md-ellipsis">
      
        MCQA Single Answer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#open-ended" class="md-nav__link">
    <span class="md-ellipsis">
      
        Open Ended
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#open-ended-with-context" class="md-nav__link">
    <span class="md-ellipsis">
      
        Open Ended with Context
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#refusal" class="md-nav__link">
    <span class="md-ellipsis">
      
        Refusal
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hallucination-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hallucination Detection
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-judge-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Judge Evaluation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-Judge Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#benefits" class="md-nav__link">
    <span class="md-ellipsis">
      
        Benefits
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metrics-produced" class="md-nav__link">
    <span class="md-ellipsis">
      
        Metrics Produced
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metrics Produced">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-individual-judge-scores" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Individual Judge Scores
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-voting-metric-recommended" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Voting Metric (Recommended)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-average-score" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Average Score
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-agreement-metric" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Agreement Metric
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#voting-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        Voting Examples
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recommendations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-output" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example Output
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#win-rate-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Win Rate Evaluation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Win Rate Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-win-rate" class="md-nav__link">
    <span class="md-ellipsis">
      
        What is Win Rate?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-differences-from-standard-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Differences from Standard Evaluation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metrics-explained" class="md-nav__link">
    <span class="md-ellipsis">
      
        Metrics Explained
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metrics Explained">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-win-rate" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Win Rate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-alpaca-win-rate" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Alpaca Win Rate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-judge-agreement" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Judge Agreement
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-position-bias" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Position Bias
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-run-win-rate-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        How to Run Win Rate Evaluation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run Win Rate Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-generate-model-outputs" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step 1: Generate Model Outputs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-create-win-rate-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step 2: Create Win Rate Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-run-win-rate-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step 3: Run Win Rate Evaluation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-view-results" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step 4: View Results
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparing-multiple-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comparing Multiple Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best Practices
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-output_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example Output
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
        References
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Running Tasks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Running Tasks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-configuration-file" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using Configuration File
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#direct-command-line" class="md-nav__link">
    <span class="md-ellipsis">
      
        Direct Command Line
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-selection-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task Selection Guide
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Evaluation Best Practices
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-resources" class="md-nav__link">
    <span class="md-ellipsis">
      
        Additional Resources
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Citation
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data Scraping
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data Scraping
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-scraping/docs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-scraping/docs/getting_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-scraping/docs/scrapers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Scrapers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-scraping/docs/examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data Processing
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data Processing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Getting Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/getting-started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/getting-started/quick-start/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/getting-started/configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Pipeline Stages
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Pipeline Stages
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/extraction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Extraction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/deduplication/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Deduplication
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/cleaning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cleaning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/filters/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Filters
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/chunking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chunking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/pii-removal/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PII Removal
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/metadata-extraction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Metadata Extraction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/export/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Export
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/pipeline-stages/qdrant/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    QDrant
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_4" >
        
          
          <label class="md-nav__link" for="__nav_6_4" id="__nav_6_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/api/core/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Core Components
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/api/stages/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Pipeline Stages
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/api/utilities/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Utilities
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/api/models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_5" >
        
          
          <label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Examples
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data-processing/docs/examples/basic-usage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Basic Usage
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-reference" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quick Reference
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#detailed-task-descriptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Detailed Task Descriptions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Detailed Task Descriptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mcqa-multiple-answer" class="md-nav__link">
    <span class="md-ellipsis">
      
        MCQA Multiple Answer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mcqa-single-answer" class="md-nav__link">
    <span class="md-ellipsis">
      
        MCQA Single Answer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#open-ended" class="md-nav__link">
    <span class="md-ellipsis">
      
        Open Ended
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#open-ended-with-context" class="md-nav__link">
    <span class="md-ellipsis">
      
        Open Ended with Context
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#refusal" class="md-nav__link">
    <span class="md-ellipsis">
      
        Refusal
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hallucination-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hallucination Detection
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-judge-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Judge Evaluation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-Judge Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#benefits" class="md-nav__link">
    <span class="md-ellipsis">
      
        Benefits
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metrics-produced" class="md-nav__link">
    <span class="md-ellipsis">
      
        Metrics Produced
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metrics Produced">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-individual-judge-scores" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Individual Judge Scores
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-voting-metric-recommended" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Voting Metric (Recommended)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-average-score" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Average Score
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-agreement-metric" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Agreement Metric
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#voting-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        Voting Examples
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recommendations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-output" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example Output
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#win-rate-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Win Rate Evaluation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Win Rate Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-win-rate" class="md-nav__link">
    <span class="md-ellipsis">
      
        What is Win Rate?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-differences-from-standard-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Differences from Standard Evaluation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metrics-explained" class="md-nav__link">
    <span class="md-ellipsis">
      
        Metrics Explained
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metrics Explained">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-win-rate" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Win Rate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-alpaca-win-rate" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Alpaca Win Rate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-judge-agreement" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Judge Agreement
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-position-bias" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Position Bias
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-run-win-rate-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        How to Run Win Rate Evaluation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run Win Rate Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-generate-model-outputs" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step 1: Generate Model Outputs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-create-win-rate-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step 2: Create Win Rate Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-run-win-rate-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step 3: Run Win Rate Evaluation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-view-results" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step 4: View Results
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparing-multiple-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comparing Multiple Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best Practices
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-output_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example Output
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
        References
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Running Tasks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Running Tasks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-configuration-file" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using Configuration File
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#direct-command-line" class="md-nav__link">
    <span class="md-ellipsis">
      
        Direct Command Line
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-selection-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task Selection Guide
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Evaluation Best Practices
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-resources" class="md-nav__link">
    <span class="md-ellipsis">
      
        Additional Resources
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Citation
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="earth-observation-evaluation-tasks">Earth Observation Evaluation Tasks</h1>
<p>This page provides a comprehensive overview of all available Earth Observation (EO) evaluation tasks in Eve-evalkit. Each task is designed to assess different capabilities of language models in the Earth Observation domain.</p>
<h2 id="quick-reference">Quick Reference</h2>
<table>
<thead>
<tr>
<th>Task Name</th>
<th>Type</th>
<th>Dataset</th>
<th>Size</th>
<th>Primary Metrics</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#mcqa-multiple-answer">MCQA Multiple Answer</a></td>
<td>Multiple Choice</td>
<td><a href="https://huggingface.co/datasets/eve-esa/eve-is-mcqa">eve-esa/eve-is-mcqa</a></td>
<td>431</td>
<td>IoU, Accuracy</td>
</tr>
<tr>
<td><a href="#mcqa-single-answer">MCQA Single Answer</a></td>
<td>Multiple Choice</td>
<td><a href="https://huggingface.co/datasets/eve-esa/mcqa-single-answer">eve-esa/mcqa-single-answer</a></td>
<td>1261</td>
<td>Accuracy</td>
</tr>
<tr>
<td><a href="#open-ended">Open Ended</a></td>
<td>Generation</td>
<td><a href="https://huggingface.co/datasets/eve-esa/open-ended">eve-esa/open-ended</a></td>
<td>1257</td>
<td>LLM as Judge, Win Rate</td>
</tr>
<tr>
<td><a href="#open-ended-with-context">Open Ended with Context</a></td>
<td>Generation</td>
<td><a href="https://huggingface.co/datasets/eve-esa/open-ended-w-context">eve-esa/open-ended-w-context</a></td>
<td>418</td>
<td>LLM Judge, Win Rate</td>
</tr>
<tr>
<td><a href="#hallucination-detection">Hallucination Detection</a></td>
<td>Classification</td>
<td><a href="https://huggingface.co/datasets/eve-esa/hallucination-detection">eve-esa/hallucination-detection</a></td>
<td>2326</td>
<td>Accuracy, Precision, Recall, F1</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="detailed-task-descriptions">Detailed Task Descriptions</h2>
<h3 id="mcqa-multiple-answer">MCQA Multiple Answer</h3>
<p><strong>Task Name:</strong> <code>is_mcqa</code> or <code>mcqa_multiple_answer</code></p>
<p><strong>Description:</strong></p>
<p>EVE-mcqa-multiple-answers consists of multiple-choice questions from Imperative Space MOOC exams where questions may have one or more correct answers. Models must identify all correct options from an arbitrary number of choices, making this a challenging task that requires comprehensive understanding rather than simple fact recall.</p>
<p><strong>How to Call:</strong></p>
<pre><code class="language-yaml">tasks:
  - name: mcqa_multiple_answers
    num_fewshot: 2
    max_tokens: 10000
</code></pre>
<p><strong>Dataset:</strong></p>
<ul>
<li><strong>Source:</strong> <a href="https://huggingface.co/datasets/eve-esa/mcqa-multiple-answers">eve-esa/mcqa-multiple-answers</a></li>
<li><strong>Split:</strong> train</li>
<li><strong>Size:</strong> 432 samples</li>
<li><strong>Structure:</strong> Each example contains a <code>Question</code>, <code>Answers</code> (list of correct labels), and <code>Choices</code> (list with labels and text)</li>
</ul>
<p><strong>Evaluation Metrics:</strong></p>
<ul>
<li><strong>IoU (Intersection over Union)</strong>: Measures partial correctness by calculating the overlap between predicted and correct answer sets. IoU = |Predicted  Correct| / |Predicted  Correct| (higher is better)</li>
<li><strong>Accuracy (Exact Match)</strong>: Binary score where 1.0 means the predicted answer set exactly matches the correct answer set (higher is better)</li>
</ul>
<p><strong>Why It's Useful:</strong></p>
<p>This task tests a model's comprehensive understanding of EO concepts where multiple aspects or factors may be simultaneously correct. The IoU metric is particularly valuable as it rewards partially correct answers, providing a more nuanced evaluation than simple exact matching. This reflects real-world scenarios where partial knowledge is still valuable.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">{
  &quot;Question&quot;: &quot;Which bands of Sentinel-2 have 10m resolution?&quot;,
  &quot;Answers&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;],
  &quot;Choices&quot;: {
    &quot;label&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;],
    &quot;text&quot;: [&quot;B2 (Blue)&quot;, &quot;B3 (Green)&quot;, &quot;B4 (Red)&quot;, &quot;B8 (NIR)&quot;]
  }
}
</code></pre>
<hr />
<h3 id="mcqa-single-answer">MCQA Single Answer</h3>
<p><strong>Task Name:</strong> <code>mcqa_single_answer</code></p>
<p><strong>Description:</strong></p>
<p>EVE-mcqa-single-answer is a traditional multiple-choice dataset with exactly one correct answer per question. Models must identify the single best option from the provided choices, testing factual knowledge and reasoning abilities in the Earth Observation domain.</p>
<p><strong>How to Call:</strong></p>
<pre><code class="language-yaml">tasks:
  - name: mcqa_single_answer
    num_fewshot: 2
    max_tokens: 10000
</code></pre>
<p><strong>Dataset:</strong></p>
<ul>
<li><strong>Source:</strong> <a href="https://huggingface.co/datasets/eve-esa/mcqa-single-answer">eve-esa/mcqa-single-answer</a></li>
<li><strong>Split:</strong> train</li>
<li><strong>Size:</strong> ~1000 samples</li>
<li><strong>Structure:</strong> Each example contains a <code>question</code>, <code>choices</code> (list of answer texts), and <code>answer</code> (single letter indicating correct choice)</li>
</ul>
<p><strong>Evaluation Metrics:</strong></p>
<ul>
<li><strong>Accuracy</strong>: Percentage of questions answered correctly (higher is better)</li>
</ul>
<p><strong>Why It's Useful:</strong></p>
<p>This task evaluates factual knowledge and reasoning abilities in scenarios where there is a single definitively correct answer. It's particularly useful for assessing fundamental EO concepts, terminology, and principles. The single-answer format reduces ambiguity and provides clear, interpretable results.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">{
  &quot;question&quot;: &quot;What is the spatial resolution of Sentinel-2's visible bands?&quot;,
  &quot;choices&quot;: [&quot;5 meters&quot;, &quot;10 meters&quot;, &quot;20 meters&quot;, &quot;60 meters&quot;],
  &quot;answer&quot;: &quot;B&quot;  # &quot;10 meters&quot;
}
</code></pre>
<hr />
<h3 id="open-ended">Open Ended</h3>
<p><strong>Task Name:</strong> <code>open_ended</code></p>
<p><strong>Description:</strong></p>
<p>EVE-open-ended is a collection of ~969 open-ended question-answer pairs focused on Earth Observation. The dataset covers a wide range of EO topics including satellite imagery analysis, remote sensing techniques, environmental monitoring, and LiDAR. Models must generate free-form responses demonstrating deep understanding without the constraints of multiple-choice formats.</p>
<p><strong>How to Call:</strong></p>
<pre><code class="language-yaml">tasks:
  - name: open_ended
    num_fewshot: 5
    max_tokens: 40000
    judge_api_key: !ref judge_api_key
    judge_base_url: !ref judge_base_url
    judge_name: !ref judge_name
</code></pre>
<p><strong>Dataset:</strong></p>
<ul>
<li><strong>Source:</strong> <a href="https://huggingface.co/datasets/eve-esa/open-ended">eve-esa/open-ended</a></li>
<li><strong>Split:</strong> train</li>
<li><strong>Size:</strong> ~969 samples</li>
<li><strong>Structure:</strong> Each example contains a <code>Question</code> and <code>Answer</code> (reference)</li>
</ul>
<p><strong>Evaluation Metrics:</strong></p>
<ul>
<li><strong>LLM as Judge</strong>: A judge model evaluates the quality, accuracy, and completeness of generated answers using strict fact-checking rules (0 = FAIL, 1 = PASS)</li>
<li><strong>Multi-Judge Support</strong>: Use multiple judges for more robust evaluation (see Multi-Judge Evaluation section below)</li>
<li><strong>Win Rate</strong>: Compare two models head-to-head using multiple LLM judges (see Win Rate Evaluation section below)</li>
<li>Alternative metrics: BLEU, ROUGE, Cosine Similarity, BERTScore</li>
</ul>
<p><strong>LLM Judge Evaluation Rules:</strong></p>
<ol>
<li><strong>Contradiction Check</strong>: Fails if the answer contains ANY fact contradicting the reference</li>
<li><strong>Relevance Check</strong>: Fails if the answer omits ESSENTIAL technical facts from the reference</li>
<li><strong>Additive Information</strong>: Additional correct information is acceptable if it doesn't contradict</li>
<li><strong>Focus on Substance</strong>: Ignores style, length, and tolerates minor phrasing differences</li>
</ol>
<p><strong>Why It's Useful:</strong></p>
<p>This task assesses a model's ability to explain concepts, provide detailed answers, and demonstrate deep understanding. It's essential for evaluating models intended for educational or explanatory applications in EO, where nuanced explanations and technical accuracy are paramount.</p>
<hr />
<h3 id="open-ended-with-context">Open Ended with Context</h3>
<p><strong>Task Name:</strong> <code>open_ended_w_context</code></p>
<p><strong>Description:</strong></p>
<p>EVE-open-ended-w-context provides open-ended questions that must be answered using 1-3 accompanying context documents. This tests the model's ability to extract and synthesize information from reference materials, making it ideal for evaluating Retrieval-Augmented Generation (RAG) systems. Not all samples contain all three documents, requiring models to handle variable numbers of context documents gracefully.</p>
<p><strong>How to Call:</strong></p>
<pre><code class="language-yaml">tasks:
  - name: open_ended_w_context
    num_fewshot: 5
    max_tokens: 40000
    judge_api_key: !ref judge_api_key
    judge_base_url: !ref judge_base_url
    judge_name: !ref judge_name
</code></pre>
<p><strong>Dataset:</strong></p>
<ul>
<li><strong>Source:</strong> <a href="https://huggingface.co/datasets/eve-esa/open-ended-w-context">eve-esa/open-ended-w-context</a></li>
<li><strong>Split:</strong> train</li>
<li><strong>Structure:</strong> Each example contains a <code>Question</code>, <code>Answer</code>, and up to three context documents (<code>Doc 1</code>, <code>Doc 2</code>, <code>Doc 3</code>)</li>
</ul>
<p><strong>Evaluation Metrics:</strong></p>
<ul>
<li><strong>LLM Judge</strong>: Evaluates whether answers are grounded in the provided context and correctly answer the question (higher is better)</li>
<li><strong>Multi-Judge Support</strong>: Use multiple judges for more robust evaluation (see Multi-Judge Evaluation section below)</li>
<li><strong>Win Rate</strong>: Compare two models head-to-head using multiple LLM judges (see Win Rate Evaluation section below)</li>
<li>Uses the same strict fact-checking evaluation rules as open-ended tasks</li>
</ul>
<p><strong>Why It's Useful:</strong></p>
<p>This task evaluates retrieval-augmented generation (RAG) capabilities, testing whether models can accurately extract information from provided documents rather than relying solely on parametric knowledge. This is crucial for applications where answers must be grounded in specific documentation or data sources. It also tests the model's ability to distinguish between context-provided information and pre-trained knowledge.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">{
  &quot;Question&quot;: &quot;What is the spatial resolution of Sentinel-2's visible bands?&quot;,
  &quot;Answer&quot;: &quot;Sentinel-2's visible bands have a spatial resolution of 10 meters.&quot;,
  &quot;Doc 1&quot;: &quot;The Sentinel-2 mission comprises a constellation...&quot;,
  &quot;Doc 2&quot;: &quot;Sentinel-2 carries the Multi-Spectral Instrument (MSI)...&quot;,
  &quot;Doc 3&quot;: &quot;&quot;  # May be empty
}
</code></pre>
<hr />
<h3 id="refusal">Refusal</h3>
<p><strong>Task Name:</strong> <code>refusal</code></p>
<p><strong>Description:</strong></p>
<p>EVE-Refusal tests whether language models can appropriately refuse to answer questions when the provided context does not contain sufficient information. The dataset presents questions alongside context documents that intentionally lack the necessary information to answer. A well-calibrated model should recognize this limitation and refuse to answer, rather than generating plausible but incorrect information.</p>
<p><strong>How to Call:</strong></p>
<pre><code class="language-yaml">tasks:
  - name: refusal
    num_fewshot: 5
    max_tokens: 40000
    judge_api_key: !ref judge_api_key
    judge_base_url: !ref judge_base_url
    judge_name: !ref judge_name
</code></pre>
<p><strong>Dataset:</strong></p>
<ul>
<li><strong>Source:</strong> <a href="https://huggingface.co/datasets/eve-esa/refusal">eve-esa/refusal</a></li>
<li><strong>Split:</strong> train</li>
<li><strong>Structure:</strong> Each example contains a <code>question</code> and <code>context</code> (insufficient for answering)</li>
<li><strong>Expected Answer:</strong> "I'm sorry, but the provided context does not contain enough information to answer that question."</li>
</ul>
<p><strong>Evaluation Metrics:</strong></p>
<ul>
<li><strong>LLM Judge</strong>: Evaluates whether the model appropriately refuses to answer or acknowledges insufficient information (higher is better)</li>
</ul>
<p><strong>Expected Behavior:</strong></p>
<ul>
<li>Recognize when provided context lacks sufficient information</li>
<li>Explicitly refuse to answer or state information is not available</li>
<li>Avoid generating plausible-sounding but fabricated information</li>
<li>Maintain accuracy and honesty over completeness</li>
</ul>
<p><strong>Why It's Useful:</strong></p>
<p>This task tests a critical safety and reliability feature: the ability to recognize limitations and avoid generating potentially incorrect information when context is insufficient. This prevents hallucinations and ensures trustworthy behavior in production systems. It's particularly important for RAG systems and applications where factual accuracy is paramount.</p>
<hr />
<h3 id="hallucination-detection">Hallucination Detection</h3>
<p><strong>Task Name:</strong> <code>hallucination_detection</code></p>
<p><strong>Description:</strong></p>
<p>EVE-Hallucination is a specialized dataset for evaluating language models' tendency to hallucinate in the Earth Observation domain. Unlike typical QA datasets, this contains deliberately hallucinated answers with detailed annotations marking which portions of text are hallucinated. The task is to identify whether a given answer contains hallucinated (false or unsupported) information.</p>
<p><strong>How to Call:</strong></p>
<pre><code class="language-yaml">tasks:
  - name: hallucination_detection
    num_fewshot: 0
    max_tokens: 100
    judge_api_key: !ref judge_api_key
    judge_base_url: !ref judge_base_url
    judge_name: !ref judge_name
</code></pre>
<p><strong>Dataset:</strong></p>
<ul>
<li><strong>Source:</strong> <a href="https://huggingface.co/datasets/eve-esa/hallucination-detection">eve-esa/hallucination-detection</a></li>
<li><strong>Split:</strong> train</li>
<li><strong>Structure:</strong> Each example contains <code>Question</code>, <code>Answer</code> (with hallucinations), <code>Soft labels</code> (probabilistic spans), and <code>Hard labels</code> (definite spans)</li>
</ul>
<p><strong>Evaluation Metrics:</strong></p>
<ul>
<li><strong>Accuracy</strong>: Overall correctness of hallucination detection (higher is better)</li>
<li><strong>Precision</strong>: Ratio of correctly identified hallucinations to all predicted hallucinations (higher is better)</li>
<li><strong>Recall</strong>: Ratio of correctly identified hallucinations to all actual hallucinations (higher is better)</li>
<li><strong>F1 Score</strong>: Harmonic mean of precision and recall (higher is better)</li>
</ul>
<p><strong>Task Levels:</strong></p>
<ol>
<li><strong>Binary Detection</strong>: Determine if answer contains any hallucinated information (yes/no)</li>
<li><strong>Hard Span Detection</strong>: Identify exact character spans that are hallucinated</li>
<li><strong>Soft Span Detection</strong>: Identify spans with confidence scores</li>
</ol>
<p><strong>Why It's Useful:</strong></p>
<p>This task evaluates a model's ability to self-assess and identify unreliable or fabricated information in EO contexts. Models with strong hallucination detection capabilities are more trustworthy and can potentially be used to validate outputs from other systems. This is crucial for safety-critical applications like climate monitoring, disaster response, and environmental analysis.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-python">{
  &quot;Question&quot;: &quot;What is the spatial resolution of Sentinel-2's visible bands?&quot;,
  &quot;Answer&quot;: &quot;Sentinel-2's visible bands have a spatial resolution of 5 meters, making it the highest resolution freely available satellite.&quot;,
  &quot;Hard labels&quot;: [[52, 60], [73, 127]]  # Character spans that are hallucinated
}
</code></pre>
<hr />
<h2 id="multi-judge-evaluation">Multi-Judge Evaluation</h2>
<p>For open-ended tasks (<code>open_ended</code>, <code>open_ended_w_context</code>, <code>open_ended_w_context_full</code>), you can use <strong>multi-judge evaluation</strong> where multiple LLM judges independently evaluate each answer. This approach provides more robust and reliable evaluation through consensus-based scoring.</p>
<h3 id="benefits">Benefits</h3>
<ul>
<li><strong>Reduced Bias</strong>: Individual judge biases are averaged out across multiple judges</li>
<li><strong>Voting Metric</strong>: Majority vote provides a robust, democratic final score</li>
<li><strong>Agreement Tracking</strong>: Monitor consensus to identify ambiguous or controversial samples</li>
<li><strong>Judge Analysis</strong>: Compare individual judges to identify systematic differences or biases</li>
</ul>
<h3 id="configuration">Configuration</h3>
<p>Define multiple judges in your <code>evals.yaml</code> configuration:</p>
<pre><code class="language-yaml">constants:
  judges:
    - name: qwen3
      model: qwen/qwen3-235b-a22b-2507
      api_key: your_openrouter_api_key
      base_url: https://openrouter.ai/api/v1/
    - name: mistral_large
      model: mistralai/mistral-large-2411
      api_key: your_openrouter_api_key
      base_url: https://openrouter.ai/api/v1/
    - name: claude_sonnet
      model: anthropic/claude-3.5-sonnet
      api_key: your_openrouter_api_key
      base_url: https://openrouter.ai/api/v1/

  tasks:
    - name: open_ended_multi_judge
      task_name: open_ended
      model_type: local-chat-completions
      num_fewshot: 0
      max_tokens: 10000
      judges: !ref judges  # Use all judges defined above
      batch_size: 15
</code></pre>
<h3 id="metrics-produced">Metrics Produced</h3>
<p>When using multi-judge evaluation, the following metrics are automatically generated:</p>
<h4 id="1-individual-judge-scores">1. Individual Judge Scores</h4>
<ul>
<li><code>llm_as_judge_{judge_name}</code>: Score from each individual judge (e.g., <code>llm_as_judge_qwen3</code>, <code>llm_as_judge_mistral_large</code>)</li>
<li>Values: 0 or 1</li>
<li>Use to identify systematic differences between judges</li>
</ul>
<h4 id="2-voting-metric-recommended">2. Voting Metric (Recommended)</h4>
<ul>
<li><code>judge_voting</code>: <strong>Majority vote result</strong></li>
<li>Returns the score that has majority support (&gt;= half+1 judges)</li>
<li>For ties (even number of judges with equal votes), defaults to 0</li>
<li>Values: 0 or 1</li>
<li><strong>This is the recommended primary metric</strong></li>
</ul>
<h4 id="3-average-score">3. Average Score</h4>
<ul>
<li><code>llm_as_judge_avg</code>: Average score across all judges</li>
<li>Values: 0.0 to 1.0</li>
<li>Provides granular scores useful for ranking models</li>
</ul>
<h4 id="4-agreement-metric">4. Agreement Metric</h4>
<ul>
<li><code>judge_agreement</code>: Percentage of samples where all judges agree</li>
<li>Values: 0.0 to 1.0</li>
<li>High agreement (&gt;0.8) indicates judges are consistent</li>
<li>Low agreement (&lt;0.5) suggests ambiguous questions or edge cases</li>
</ul>
<h3 id="voting-examples">Voting Examples</h3>
<p><strong>With 2 judges:</strong>
- Both vote 1  voting = 1
- Both vote 0  voting = 0
- 1 votes 1, 1 votes 0  voting = 0 (tie, no majority)</p>
<p><strong>With 3 judges:</strong>
- 2 vote 1, 1 votes 0  voting = 1 (majority)
- 1 votes 1, 2 vote 0  voting = 0 (majority)
- All vote 1  voting = 1 (unanimous)</p>
<p><strong>With 5 judges:</strong>
- 3 vote 1, 2 vote 0  voting = 1 (majority)
- 2 vote 1, 3 vote 0  voting = 0 (majority)</p>
<h3 id="recommendations">Recommendations</h3>
<p><strong>Number of Judges:</strong>
- <strong>3 judges</strong>: Good balance between cost and reliability (recommended)
- <strong>5 judges</strong>: Better for high-stakes evaluations
- <strong>2 judges</strong>: Avoid if possible (risk of ties with no clear majority)</p>
<p><strong>Judge Selection:</strong>
- Use diverse models (different architectures/providers)
- Mix model sizes (small + large models)
- Include both specialized and general-purpose models
- Example: Claude, GPT-4, Mistral Large, Qwen</p>
<p><strong>Cost Optimization:</strong>
1. Start with 3 judges on a small sample (limit: 10-50)
2. Analyze the agreement rate
3. If agreement is high (&gt;0.8), consider using single judge or voting metric
4. If agreement is low (&lt;0.5), investigate question quality or add more judges</p>
<h3 id="example-output">Example Output</h3>
<pre><code class="language-json">{
  &quot;results&quot;: {
    &quot;open_ended&quot;: {
      &quot;llm_as_judge_qwen3&quot;: 0.75,
      &quot;llm_as_judge_mistral_large&quot;: 0.80,
      &quot;llm_as_judge_claude_sonnet&quot;: 0.78,
      &quot;llm_as_judge_avg&quot;: 0.777,
      &quot;judge_agreement&quot;: 0.65,
      &quot;judge_voting&quot;: 0.80
    }
  }
}
</code></pre>
<p>In this example:
- Individual judges scored 75%, 80%, and 78%
- Overall average is 77.7%
- Judges fully agreed on 65% of samples
- <strong>Majority vote gave 80% (recommended metric to report)</strong></p>
<hr />
<h2 id="win-rate-evaluation">Win Rate Evaluation</h2>
<p>For open-ended tasks (<code>open_ended</code>, <code>open_ended_w_context</code>), you can perform <strong>win rate evaluation</strong> to compare two models head-to-head using multiple LLM judges. This separate evaluation script provides comparative analysis between model outputs, complementing the standard LLM-as-judge metrics.</p>
<h3 id="what-is-win-rate">What is Win Rate?</h3>
<p>Win rate evaluation compares the outputs of two models (Model A vs Model B) on the same questions and determines which model provides better answers according to independent LLM judges. This approach is particularly useful for:</p>
<ul>
<li><strong>Model Selection</strong>: Directly compare two models to identify which performs better</li>
<li><strong>Model Improvement</strong>: Assess whether a new model version improves over a baseline</li>
<li><strong>Ablation Studies</strong>: Evaluate the impact of specific model changes or training approaches</li>
<li><strong>Benchmark Comparison</strong>: Compare your model against established baselines or competitors</li>
</ul>
<h3 id="key-differences-from-standard-evaluation">Key Differences from Standard Evaluation</h3>
<p>The win rate evaluation is a <strong>separate script</strong> with its own configuration format and workflow:</p>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Standard Evaluation</th>
<th>Win Rate Evaluation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Purpose</strong></td>
<td>Evaluate single model quality</td>
<td>Compare two models head-to-head</td>
</tr>
<tr>
<td><strong>Script</strong></td>
<td><code>scripts/evaluate.py</code></td>
<td><code>metrics/win_rate/win_rate_evaluation.py</code></td>
</tr>
<tr>
<td><strong>Configuration</strong></td>
<td><code>evals.yaml</code></td>
<td>Separate YAML config (e.g., <code>win_rate_config.yaml</code>)</td>
</tr>
<tr>
<td><strong>Input</strong></td>
<td>Live model API</td>
<td>Pre-generated CSV files from standard evaluation</td>
</tr>
<tr>
<td><strong>Output Format</strong></td>
<td>Standard metrics (accuracy, F1)</td>
<td>Win rates, alpaca win rates, judge agreement</td>
</tr>
<tr>
<td><strong>Judges</strong></td>
<td>Single or multi-judge per eval</td>
<td>Multiple judges comparing two outputs</td>
</tr>
<tr>
<td><strong>WandB Logging</strong></td>
<td>Evaluation results</td>
<td>Win rate metrics, visualizations, judge rationales</td>
</tr>
</tbody>
</table>
<h3 id="metrics-explained">Metrics Explained</h3>
<h4 id="1-win-rate">1. Win Rate</h4>
<p>Percentage of questions where each model won according to each judge.</p>
<p><strong>Formula:</strong></p>
<pre><code>Win Rate = (Number of Wins / Total Evaluations)  100%
</code></pre>
<p><strong>Calculation Process:</strong>
- For each question, each judge compares Model A vs Model B outputs
- Judge decides: Model A wins, Model B wins, or Tie
- Win rate = (wins / total evaluations)  100%
- Aggregate win rate = average win rate across all judges</p>
<p><strong>Interpreting Win Rate Values:</strong>
- <strong>0.50 (50%)</strong>: Models perform equally well (perfect tie across all questions)
- <strong>&gt; 0.50</strong>: Model is better than its competitor
  - 0.55-0.60: Slight advantage
  - 0.60-0.70: Clear advantage
  - 0.70+: Strong advantage
- <strong>&lt; 0.50</strong>: Model is worse than its competitor
- <strong>Win Rate Difference</strong>: The gap between Model A and Model B
  - Difference &lt; 0.05: Negligible difference
  - Difference 0.05-0.10: Noticeable difference
  - Difference &gt; 0.10: Significant performance gap</p>
<p><strong>Logged Metrics:</strong>
- <code>win_rate/{judge_name}/{model_name}</code>: Win rate for each model per judge (0.0 to 1.0)
- <code>aggregate/{model_name}_win_rate</code>: Aggregate win rate across all judges
- <code>aggregate/avg_{model_name}_win_rate</code>: Average win rate across judges
- <code>aggregate/win_rate_difference</code>: Difference between Model A and Model B win rates</p>
<p><strong>Example:</strong></p>
<pre><code>Model A wins: 72 questions
Model B wins: 25 questions
Ties: 3 questions
Total: 100 questions

Model A Win Rate = 72/100 = 0.72 (72%)
Model B Win Rate = 25/100 = 0.25 (25%)
Win Rate Difference = 0.72 - 0.25 = 0.47 (47% gap - significant advantage for Model A)
</code></pre>
<h4 id="2-alpaca-win-rate">2. Alpaca Win Rate</h4>
<p>A more nuanced metric that counts ties as half a win for each model, based on the <a href="https://github.com/tatsu-lab/alpaca_eval">AlpacaEval</a> framework.</p>
<p><strong>Formula:</strong></p>
<pre><code>Alpaca Win Rate = (Number of Wins + 0.5  Number of Ties) / Total Evaluations
</code></pre>
<p><strong>Why Use Alpaca Win Rate?</strong>
- Treats ties as split decisions, giving partial credit to both models
- More granular than standard win rate when there are many ties
- Better reflects cases where models perform similarly on some questions
- Recommended by AlpacaEval for instruction-following model comparisons</p>
<p><strong>Interpreting Alpaca Win Rate Values:</strong>
- <strong>0.50 (50%)</strong>: Models perform equally well
- <strong>&gt; 0.50</strong>: Model is better (same interpretation as standard win rate)
- Alpaca win rate is always  standard win rate (due to partial credit for ties)
- Use alpaca win rate when you have many ties and want more nuanced comparison</p>
<p><strong>Logged Metrics:</strong>
- <code>alpaca_win_rate/{judge_name}/{model_name}</code>: Alpaca win rate per judge
- <code>aggregate/{model_name}_alpaca_win_rate</code>: Aggregate alpaca win rate
- <code>aggregate/avg_{model_name}_alpaca_win_rate</code>: Average alpaca win rate across judges
- <code>aggregate/alpaca_win_rate_difference</code>: Difference between Model A and Model B alpaca win rates</p>
<p><strong>Example:</strong></p>
<pre><code>Model A wins: 72 questions
Model B wins: 25 questions
Ties: 3 questions
Total: 100 questions

Model A Alpaca Win Rate = (72 + 0.53)/100 = 73.5/100 = 0.735 (73.5%)
Model B Alpaca Win Rate = (25 + 0.53)/100 = 26.5/100 = 0.265 (26.5%)

Note: Both models get partial credit for the 3 ties
</code></pre>
<p><strong>Reference:</strong> <a href="https://github.com/tatsu-lab/alpaca_eval">AlpacaEval - Automatic Evaluator for Instruction-following LLMs</a></p>
<h4 id="3-judge-agreement">3. Judge Agreement</h4>
<p>Measures how consistently judges agree on which model is better:</p>
<ul>
<li><strong>Unanimous (1.0)</strong>: All judges made the same decision</li>
<li><strong>Majority (0.5-0.99)</strong>: Most judges agreed on winner</li>
<li><strong>Split (&lt; 0.5)</strong>: Judges were evenly divided</li>
</ul>
<p><strong>Interpreting Agreement:</strong>
- <strong>&gt; 0.80</strong>: High agreement - clear quality difference or consistent evaluation
- <strong>0.50-0.80</strong>: Moderate agreement - some subjective variation among judges
- <strong>&lt; 0.50</strong>: Low agreement - questions may be ambiguous or judges have different criteria</p>
<h4 id="4-position-bias">4. Position Bias</h4>
<p>Analysis of whether judges are biased toward answers shown in position A vs B. The evaluation randomizes answer positions to mitigate this bias.</p>
<p><strong>What to Look For:</strong>
- Position bias close to 0.50 (50%) indicates no position bias
- Significant deviation from 0.50 suggests judges prefer one position
- Randomization helps ensure fair comparison despite any position bias</p>
<h3 id="how-to-run-win-rate-evaluation">How to Run Win Rate Evaluation</h3>
<h4 id="step-1-generate-model-outputs">Step 1: Generate Model Outputs</h4>
<p>First, run standard evaluation to generate CSV files with model outputs:</p>
<pre><code class="language-bash">python scripts/evaluate.py evals.yaml
</code></pre>
<p>This creates CSV files in your output directory (e.g., <code>evals_outputs/{model_name}/samples_open_ended.csv</code>) with columns:
- <code>doc\.Question</code>: The question text
- <code>target</code>: The reference/ground truth answer
- <code>filtered_resps</code>: The model's response</p>
<h4 id="step-2-create-win-rate-configuration">Step 2: Create Win Rate Configuration</h4>
<p>Create a YAML configuration file (e.g., <code>win_rate_config.yaml</code>):</p>
<pre><code class="language-yaml"># Task type for metrics logging
task: &quot;open_ended&quot;  # or &quot;open_ended_w_context&quot;

# Models to compare
model_a:
  - name: &quot;model-a-name&quot;
    file: &quot;path/to/model_a_output.csv&quot;

model_b:
  - name: &quot;model-b-name&quot;
    file: &quot;path/to/model_b_output.csv&quot;

# LLM Judges configuration
judges:
  - name: &quot;mistral-large&quot;
    model: &quot;mistral-large-2512&quot;
    api_key: &quot;${MISTRAL_API_KEY}&quot;
    base_url: &quot;https://api.mistral.ai/v1&quot;

  - name: &quot;gpt-4-mini&quot;
    model: &quot;openai/gpt-4.1-mini&quot;
    api_key: &quot;${OPENROUTER_API_KEY}&quot;
    base_url: &quot;https://openrouter.ai/api/v1/&quot;

  - name: &quot;qwen3-235b&quot;
    model: &quot;qwen/qwen3-235b-a22b-2507&quot;
    api_key: &quot;${OPENROUTER_API_KEY}&quot;
    base_url: &quot;https://openrouter.ai/api/v1/&quot;

# Evaluation settings
evaluation:
  limit: null  # Set to N to limit to first N questions, or null for all
  max_workers: 20  # Number of parallel threads
  rate_limit_delay: 0.05  # Delay between API calls (seconds)
  random_seed: 42  # For reproducibility (null = random)

# Output settings
output:
  save_results: true
  save_visualizations: true
  output_dir: &quot;win_rate_results&quot;
  results_filename: &quot;results_{model_a}_vs_{model_b}.csv&quot;
  summary_filename: &quot;summary_{model_a}_vs_{model_b}.csv&quot;
  visualization_filename: &quot;comparison_{model_a}_vs_{model_b}.png&quot;

# Weights &amp; Biases configuration
wandb:
  enabled: true
  project: &quot;eve-win-rate-evaluation&quot;
  entity: your-wandb-username  # or null for default
  run_name: &quot;{model_a}_vs_{model_b}&quot;
  tags:
    - &quot;win-rate&quot;
    - &quot;llm-judge&quot;

  # What to log
  log:
    win_rates: true
    accuracy_rates: true
    judge_agreement: true
    position_bias: true
    visualizations: true
    raw_results: true
    sample_rationales: true
    sample_count: 5
</code></pre>
<h4 id="step-3-run-win-rate-evaluation">Step 3: Run Win Rate Evaluation</h4>
<pre><code class="language-bash">python metrics/win_rate/win_rate_evaluation.py --config win_rate_config.yaml
</code></pre>
<h4 id="step-4-view-results">Step 4: View Results</h4>
<p>The script generates:</p>
<ol>
<li><strong>CSV Results</strong> (<code>win_rate_results/results_*.csv</code>): Complete evaluation data with all judge decisions</li>
<li><strong>Summary CSV</strong> (<code>win_rate_results/summary_*.csv</code>): Win rate statistics per judge</li>
<li><strong>Visualizations</strong> (<code>win_rate_results/comparison_*.png</code>): Charts showing win rates</li>
<li><strong>WandB Dashboard</strong>: Interactive results with metrics, visualizations, and sample rationales</li>
</ol>
<h3 id="comparing-multiple-models">Comparing Multiple Models</h3>
<p>You can compare multiple models pairwise by configuring lists for <code>model_a</code> and <code>model_b</code>:</p>
<pre><code class="language-yaml">model_a:
  - name: &quot;eve_v04&quot;
    file: &quot;generations/open_ended/scoring_eve_v04_open_ended_0_shot.csv&quot;
  - name: &quot;eve_v05&quot;
    file: &quot;generations/open_ended/scoring_eve_v05_open_ended_0_shot.csv&quot;

model_b:
  - name: &quot;mistral-small&quot;
    file: &quot;generations/open_ended/scoring_mistral-small_open_ended_0_shot.csv&quot;
  - name: &quot;llama-4-scout&quot;
    file: &quot;generations/open_ended/scoring_llama-4-scout_open_ended_0_shot.csv&quot;
</code></pre>
<p>This will run all pairwise comparisons: eve_v04 vs mistral-small, eve_v04 vs llama-4-scout, eve_v05 vs mistral-small, eve_v05 vs llama-4-scout.</p>
<h3 id="best-practices">Best Practices</h3>
<ol>
<li><strong>Number of Judges</strong>: Use 3-5 judges for robust evaluation</li>
<li><strong>Judge Diversity</strong>: Select judges from different model families (e.g., GPT, Claude, Mistral, Qwen)</li>
<li><strong>Rate Limiting</strong>: Adjust <code>rate_limit_delay</code> if hitting API rate limits</li>
<li><strong>Reproducibility</strong>: Set <code>random_seed</code> to a fixed value for reproducible position randomization</li>
<li><strong>Testing</strong>: Start with <code>limit: 10</code> to test configuration before running full evaluation</li>
<li><strong>WandB Tracking</strong>: Enable wandb logging to track experiments and compare runs</li>
</ol>
<h3 id="example-output_1">Example Output</h3>
<p>After running win rate evaluation, you'll see output like:</p>
<pre><code>Model A: eve_v05
Model B: mistral-small-3.2-24b

=== Aggregate Results ===
eve_v05:
  Win Rate: 0.72 (72%)
  Alpaca Win Rate: 0.75 (75%)

mistral-small-3.2-24b:
  Win Rate: 0.28 (28%)
  Alpaca Win Rate: 0.25 (25%)

Judge Agreement: 0.68 (68% unanimous decisions)

WandB Run: https://wandb.ai/your-entity/eve-win-rate-evaluation/runs/...
</code></pre>
<p><strong>Interpretation</strong>: eve_v05 clearly outperforms mistral-small-3.2-24b with a 44% win rate gap (0.72 - 0.28), indicating strong superiority across the evaluated questions.</p>
<h3 id="references">References</h3>
<ul>
<li><strong>AlpacaEval Framework</strong>: <a href="https://github.com/tatsu-lab/alpaca_eval">https://github.com/tatsu-lab/alpaca_eval</a></li>
<li><strong>Full Documentation</strong>: See <code>WIN_RATE_EVALUATION_README.md</code> in the repository root</li>
<li><strong>Example Configurations</strong>: See <code>metrics/win_rate/win_rate_open_ended_example.yaml</code></li>
</ul>
<hr />
<h2 id="running-tasks">Running Tasks</h2>
<h3 id="using-configuration-file">Using Configuration File</h3>
<p>Add tasks to your <code>evals.yaml</code>:</p>
<pre><code class="language-yaml">constants:
  judge_api_key: your-judge-api-key
  judge_base_url: https://openrouter.ai/api/v1
  judge_name: mistralai/mistral-large-2411
  tasks:
    - name: mcqa_multiple_answers
      num_fewshot: 2
      max_tokens: 10000
    - name: hallucination_detection
      num_fewshot: 0
      max_tokens: 100

models:
  - name: your-model-name
    base_url: https://api.provider.com/v1/chat/completions
    api_key: your-api-key
    temperature: 0.1
    num_concurrent: 5
    tasks: !ref tasks

output_dir: evals_outputs
</code></pre>
<p>Then run:</p>
<pre><code class="language-bash">python scripts/evaluate.py evals.yaml
</code></pre>
<h3 id="direct-command-line">Direct Command Line</h3>
<pre><code class="language-bash">lm_eval --model openai-chat-completions \
        --model_args base_url=https://api.provider.com,model=model-name,num_concurrent=5 \
        --tasks {task_name} \
        --include tasks \
        --num_fewshot 0 \
        --output_path ./outputs \
        --log_samples \
        --apply_chat_template
</code></pre>
<p>For tasks using LLM-as-judge metrics, set environment variables:</p>
<pre><code class="language-bash">export JUDGE_API_KEY=your-judge-api-key
export JUDGE_BASE_URL=https://api.provider.com/v1
export JUDGE_NAME=judge-model-name
</code></pre>
<hr />
<h2 id="task-selection-guide">Task Selection Guide</h2>
<p>Choose tasks based on your evaluation goals:</p>
<p><strong>Factual Knowledge:</strong>
- <code>mcqa_single_answer</code> - Single correct answer questions
- <code>mcqa_multiple_answers</code> - Multiple correct answers with partial credit</p>
<p><strong>Generation Quality:</strong>
- <code>open_ended</code> - Free-form explanatory answers</p>
<p><strong>Grounded Generation (RAG):</strong>
- <code>open_ended_w_context</code> - Answer questions using provided documents
- <code>refusal</code> - Recognize when context is insufficient</p>
<p><strong>Reliability &amp; Safety:</strong>
- <code>hallucination_detection</code> - Identify fabricated information
- <code>refusal</code> - Avoid answering without sufficient information</p>
<p><strong>Comprehensive Evaluation:</strong>
- Run all tasks for a complete assessment across different capabilities</p>
<hr />
<h2 id="evaluation-best-practices">Evaluation Best Practices</h2>
<ol>
<li><strong>Use Few-Shot Examples</strong>: Most tasks benefit from few-shot examples (typically 2-5) to demonstrate the expected format</li>
<li><strong>Set Appropriate Timeouts</strong>: Some tasks require longer generation, so adjust timeouts accordingly</li>
<li><strong>Configure Judge Model</strong>: For LLM-as-judge tasks, choose a capable judge model (e.g., GPT-4, Claude 3.5 Sonnet, Mistral Large)</li>
<li><strong>Log Samples</strong>: Always use <code>--log_samples</code> to inspect individual predictions and understand model behavior</li>
<li><strong>Monitor Costs</strong>: LLM-as-judge evaluation can be expensive; consider using smaller subsets for initial testing</li>
</ol>
<hr />
<h2 id="additional-resources">Additional Resources</h2>
<ul>
<li><strong>Dataset Repository:</strong> <a href="https://huggingface.co/eve-esa">https://huggingface.co/eve-esa</a></li>
<li><strong>GitHub Repository:</strong> <a href="https://github.com/eve-esa/eve-evaluation">https://github.com/eve-esa/eve-evaluation</a></li>
<li><strong>LM Evaluation Harness:</strong> <a href="https://github.com/EleutherAI/lm-evaluation-harness">https://github.com/EleutherAI/lm-evaluation-harness</a></li>
</ul>
<hr />
<h2 id="citation">Citation</h2>
<p>If you use these tasks or datasets in your research, please cite:</p>
<pre><code class="language-bibtex">@misc{eve2025,
  title={EVE: Earth Virtual Expert},
  author={ESA},
  year={2025},
  publisher={HuggingFace},
  url={https://huggingface.co/eve-esa/eve_v0.1}
}
</code></pre>
<p>For the underlying evaluation framework:</p>
<pre><code class="language-bibtex">@software{eval-harness,
  author       = {Gao, Leo and others},
  title        = {A framework for few-shot language model evaluation},
  month        = sep,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {v0.0.1},
  doi          = {10.5281/zenodo.5371628},
  url          = {https://doi.org/10.5281/zenodo.5371628}
}
</code></pre>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Implemented by <a href="https://picampus-school.com/" target="_blank">Pi School</a>, <a href="https://www.imperative.space/" target="_blank">Imperative Space</a>
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://eve.philab.esa.int/" target="_blank" rel="noopener" title="Project Page" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M351.9 280H161c2.9 64.5 17.2 123.9 37.5 167.4 11.4 24.5 23.7 41.8 35.1 52.4 11.2 10.5 18.9 12.2 22.9 12.2s11.7-1.7 22.9-12.2c11.4-10.6 23.7-28 35.1-52.4 20.3-43.5 34.6-102.9 37.5-167.4zm-191-48h190.9c-2.8-64.5-17.1-123.9-37.4-167.4-11.4-24.4-23.7-41.8-35.1-52.4C268.1 1.7 260.4 0 256.4 0s-11.7 1.7-22.9 12.2c-11.4 10.6-23.7 28-35.1 52.4-20.3 43.5-34.6 102.9-37.5 167.4m-48 0c3.5-85.6 25.6-165.1 57.9-217.3C78.7 47.3 10.9 131.2 1.5 232zM1.5 280c9.4 100.8 77.2 184.7 169.3 217.3-32.3-52.2-54.4-131.7-57.9-217.3zm398.4 0c-3.5 85.6-25.6 165.1-57.9 217.3 92.1-32.7 159.9-116.5 169.3-217.3zm111.4-48C501.9 131.2 434.1 47.3 342 14.7c32.3 52.2 54.4 131.7 57.9 217.3z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://github.com/eve-esa/eve-evaluation" target="_blank" rel="noopener" title="GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="https://huggingface.co/eve-esa" target="_blank" rel="noopener" title="Hugging Face" class="md-social__link">
      <svg width="256" height="256" viewBox="0 0 256 256" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M230.721 172.7C230.183 170.673 229.313 168.75 228.146 167.008C228.396 166.091 228.587 165.159 228.714 164.217C229.543 158.241 227.471 152.77 223.567 148.537C221.452 146.225 219.185 144.698 216.784 143.761C218.36 137.018 219.157 130.117 219.161 123.193C219.161 120.03 218.982 116.932 218.682 113.88C218.526 112.356 218.337 110.836 218.115 109.32C217.428 104.847 216.408 100.431 215.064 96.11C214.183 93.2707 213.164 90.476 212.01 87.736C210.281 83.6782 208.262 79.75 205.969 75.982C204.465 73.475 202.827 71.0508 201.062 68.72C200.197 67.543 199.296 66.3938 198.358 65.274C195.58 61.898 192.561 58.7277 189.325 55.788C188.25 54.7997 187.145 53.8453 186.01 52.926C184.893 51.9943 183.751 51.0927 182.586 50.222C180.241 48.4766 177.818 46.8392 175.324 45.315C161.543 36.945 145.382 32.145 128.109 32.145C77.817 32.145 37.057 72.907 37.057 123.196C37.055 130.208 37.867 137.196 39.477 144.02C37.317 144.958 35.247 146.42 33.327 148.535C29.424 152.766 27.351 158.217 28.18 164.193C28.306 165.142 28.495 166.082 28.747 167.006C27.5811 168.749 26.7117 170.673 26.174 172.7C24.974 177.261 25.369 181.374 26.894 184.978C25.236 189.688 25.65 194.704 27.809 199.065C29.379 202.25 31.626 204.714 34.396 206.916C37.689 209.534 41.811 211.758 46.783 213.892C52.715 216.422 59.956 218.799 63.249 219.671C71.755 221.873 79.911 223.269 88.177 223.337C99.954 223.446 110.096 220.677 117.357 213.59C120.924 214.027 124.515 214.246 128.109 214.244C131.906 214.236 135.699 213.997 139.467 213.529C146.711 220.661 156.892 223.455 168.712 223.343C176.977 223.277 185.133 221.881 193.617 219.676C196.932 218.804 204.17 216.427 210.105 213.897C215.077 211.76 219.199 209.536 222.514 206.922C225.263 204.719 227.508 202.256 229.079 199.071C231.26 194.709 231.652 189.693 230.017 184.983C231.527 181.379 231.92 177.257 230.721 172.7ZM222.281 184.673C223.952 187.844 224.059 191.427 222.585 194.764C220.349 199.821 214.795 203.805 204.008 208.082C197.3 210.742 191.158 212.443 191.104 212.458C182.232 214.759 174.208 215.928 167.262 215.928C155.76 215.928 147.201 212.754 141.773 206.486C132.594 208.05 123.222 208.103 114.026 206.644C108.591 212.808 100.081 215.928 88.676 215.928C81.729 215.928 73.706 214.759 64.833 212.458C64.779 212.443 58.639 210.742 51.929 208.082C41.143 203.805 35.587 199.824 33.352 194.764C31.878 191.427 31.985 187.844 33.656 184.673C33.81 184.378 33.976 184.091 34.153 183.813C33.1516 182.309 32.4799 180.61 32.182 178.827C31.8842 177.045 31.967 175.22 32.425 173.472C33.089 170.949 34.46 168.851 36.322 167.344C35.425 165.87 34.8365 164.23 34.592 162.522C34.056 158.808 35.289 155.1 38.062 152.076C40.222 149.723 43.275 148.428 46.655 148.428H46.745C44.1965 140.259 42.9044 131.75 42.913 123.193C42.913 76.522 80.749 38.683 127.427 38.683C174.104 38.683 211.94 76.518 211.94 123.193C211.947 131.773 210.646 140.304 208.081 148.492C208.489 148.452 208.889 148.432 209.282 148.431C212.662 148.431 215.716 149.726 217.874 152.079C220.647 155.1 221.881 158.811 221.344 162.525C221.1 164.233 220.511 165.873 219.615 167.347C221.477 168.854 222.849 170.952 223.512 173.475C223.97 175.223 224.053 177.048 223.755 178.831C223.458 180.613 222.786 182.312 221.784 183.816C221.961 184.091 222.129 184.378 222.281 184.673Z" fill="white"/>
<path d="M221.784 183.816C222.786 182.312 223.458 180.613 223.756 178.831C224.053 177.048 223.97 175.223 223.512 173.475C222.848 170.952 221.476 168.854 219.615 167.347C220.512 165.873 221.1 164.233 221.344 162.525C221.881 158.811 220.648 155.103 217.874 152.079C215.716 149.726 212.662 148.431 209.282 148.431C208.889 148.431 208.489 148.452 208.081 148.492C210.643 140.304 211.942 131.774 211.933 123.195C211.933 76.5231 174.097 38.6851 127.424 38.6851C80.75 38.6851 42.9099 76.5191 42.9099 123.195C42.9015 131.752 44.1936 140.261 46.742 148.43H46.6519C43.2719 148.43 40.219 149.724 38.06 152.077C35.287 155.098 34.0529 158.81 34.5899 162.523C34.8346 164.231 35.4231 165.872 36.3199 167.346C34.4579 168.852 33.086 170.95 32.422 173.473C31.9642 175.222 31.8817 177.047 32.1799 178.83C32.4781 180.612 33.1501 182.312 34.1519 183.816C33.9739 184.094 33.8099 184.381 33.6549 184.676C31.9849 187.847 31.877 191.43 33.352 194.767C35.588 199.824 41.1419 203.808 51.9289 208.085C58.6359 210.745 64.779 212.446 64.833 212.461C73.705 214.762 81.729 215.931 88.675 215.931C100.081 215.931 108.591 212.811 114.026 206.647C123.222 208.106 132.594 208.052 141.773 206.489C147.201 212.757 155.76 215.931 167.262 215.931C174.208 215.931 182.232 214.762 191.103 212.461C191.158 212.446 197.298 210.745 204.008 208.085C214.795 203.808 220.35 199.824 222.585 194.767C224.059 191.43 223.952 187.847 222.281 184.676C222.129 184.379 221.961 184.091 221.784 183.816ZM110.137 196.997C109.669 197.815 109.168 198.614 108.635 199.391C107.23 201.448 105.382 203.02 103.237 204.188C99.1369 206.424 93.947 207.205 88.675 207.205C80.346 207.205 71.808 205.256 67.023 204.015C66.787 203.954 37.689 195.735 41.373 188.739C41.993 187.562 43.0129 187.092 44.2979 187.092C49.4849 187.092 58.9299 194.816 62.9889 194.816C63.8959 194.816 64.5359 194.43 64.7969 193.488C66.5269 187.284 38.5039 184.676 40.8639 175.692C41.2799 174.102 42.41 173.456 43.998 173.456C50.856 173.455 66.248 185.516 69.467 185.516C69.714 185.516 69.8909 185.443 69.9869 185.291C70.0009 185.268 70.015 185.246 70.028 185.222C71.539 182.727 70.6719 180.913 60.3209 174.573L59.3269 173.968C47.9359 167.074 39.9409 162.925 44.4879 157.975C45.0109 157.404 45.7529 157.151 46.6539 157.151C47.7219 157.151 49.0149 157.508 50.4389 158.108C56.4549 160.645 64.793 167.564 68.276 170.581C68.8239 171.057 69.3683 171.538 69.9089 172.022C69.9089 172.022 74.319 176.608 76.985 176.608C77.599 176.608 78.1199 176.366 78.4729 175.768C80.364 172.58 60.9099 157.838 59.8129 151.755C59.0689 147.634 60.3349 145.546 62.6749 145.546C63.7879 145.546 65.1459 146.02 66.6449 146.971C71.2949 149.922 80.2729 165.35 83.5599 171.352C84.6619 173.363 86.5429 174.213 88.2379 174.213C91.6009 174.213 94.2299 170.87 88.5459 166.622C80.0029 160.23 83.001 149.782 87.078 149.139C87.252 149.111 87.4279 149.097 87.6029 149.097C91.3109 149.097 92.9459 155.486 92.9459 155.486C92.9459 155.486 97.7399 167.524 105.975 175.753C113.447 183.222 114.491 189.351 110.137 196.997ZM136.766 198.407L136.339 198.458L135.611 198.541C135.228 198.581 134.844 198.619 134.459 198.654L134.084 198.688L133.741 198.717L133.255 198.756L132.718 198.795L132.182 198.83L132.063 198.838C131.923 198.846 131.783 198.855 131.641 198.862L131.462 198.872C131.296 198.881 131.13 198.889 130.962 198.896L130.381 198.921L129.854 198.939L129.502 198.949H129.323C129.213 198.949 129.104 198.955 128.994 198.956H128.82C128.71 198.956 128.601 198.956 128.491 198.961L128.043 198.967H127.418C126.927 198.967 126.437 198.962 125.949 198.952L125.553 198.943C125.44 198.943 125.327 198.938 125.216 198.934L124.796 198.922L124.275 198.902L123.805 198.881L123.684 198.876L123.237 198.853C123.112 198.846 122.989 198.84 122.865 198.831L122.576 198.814C122.213 198.791 121.85 198.766 121.487 198.738L121.107 198.707C120.947 198.695 120.787 198.68 120.628 198.666C120.441 198.65 120.254 198.632 120.067 198.614C119.754 198.585 119.441 198.553 119.128 198.519H119.113C123.683 188.324 121.372 178.802 112.137 169.575C106.08 163.526 102.051 154.594 101.215 152.633C99.5229 146.828 95.045 140.375 87.608 140.375C86.979 140.375 86.351 140.425 85.73 140.523C82.472 141.036 79.624 142.911 77.592 145.733C75.396 143.002 73.262 140.831 71.332 139.605C68.422 137.76 65.5179 136.824 62.6889 136.824C59.1579 136.824 56.0019 138.274 53.8019 140.904L53.7459 140.971C53.7039 140.798 53.6639 140.625 53.6229 140.451L53.6179 140.428C53.1992 138.638 52.8477 136.833 52.5639 135.016C52.5639 135.004 52.5639 134.992 52.5579 134.98C52.5359 134.843 52.5159 134.705 52.4949 134.568C52.4334 134.162 52.3757 133.755 52.3219 133.348C52.2979 133.163 52.2719 132.978 52.2489 132.793L52.1809 132.238C52.1589 132.053 52.1409 131.885 52.1209 131.709L52.115 131.665C52.0351 130.945 51.9651 130.225 51.9049 129.503L51.8829 129.226L51.8479 128.754C51.8379 128.625 51.8279 128.495 51.8209 128.365C51.8209 128.334 51.8159 128.304 51.8149 128.275C51.7895 127.913 51.7678 127.55 51.7499 127.187C51.7399 126.998 51.7299 126.81 51.7219 126.62L51.7019 126.124L51.6969 125.974L51.6809 125.517L51.6709 125.128C51.6709 124.973 51.6629 124.818 51.6609 124.663C51.6579 124.508 51.6539 124.338 51.6529 124.174C51.6509 124.01 51.6529 123.848 51.6479 123.685C51.6439 123.521 51.6479 123.358 51.6479 123.195C51.6479 81.3421 85.5789 47.4111 127.436 47.4111C169.292 47.4111 203.222 81.3411 203.222 123.195V124.174C203.222 124.337 203.217 124.501 203.214 124.663C203.214 124.798 203.208 124.931 203.204 125.068C203.204 125.188 203.199 125.309 203.195 125.425C203.195 125.578 203.186 125.731 203.181 125.884V125.896L203.16 126.427C203.153 126.582 203.147 126.738 203.139 126.893L203.134 127.003L203.107 127.499C203.048 128.562 202.967 129.623 202.866 130.683V130.696C202.849 130.87 202.832 131.044 202.813 131.218L202.768 131.629L202.679 132.433L202.628 132.84L202.565 133.319C202.542 133.493 202.519 133.668 202.493 133.841C202.467 134.036 202.438 134.23 202.409 134.424L202.34 134.883L202.258 135.403C202.23 135.576 202.2 135.748 202.168 135.92C202.135 136.093 202.109 136.265 202.079 136.437C202.019 136.781 201.956 137.125 201.89 137.468C201.789 137.981 201.686 138.493 201.58 139.005L201.47 139.512C201.434 139.681 201.395 139.851 201.357 140.02C199.224 137.947 196.399 136.818 193.284 136.818C190.457 136.818 187.55 137.753 184.641 139.598C182.711 140.824 180.578 142.996 178.381 145.726C176.346 142.904 173.498 141.029 170.242 140.516C169.621 140.418 168.993 140.368 168.364 140.368C160.925 140.368 156.45 146.821 154.757 152.626C153.917 154.587 149.887 163.519 143.825 169.577C134.596 178.775 132.268 188.254 136.766 198.407ZM215.007 177.998L214.977 178.087C214.901 178.288 214.813 178.484 214.714 178.674C214.639 178.814 214.558 178.95 214.47 179.082C214.303 179.331 214.12 179.569 213.921 179.793C213.875 179.845 213.831 179.897 213.779 179.948C213.707 180.025 213.634 180.101 213.559 180.175C212.213 181.509 210.161 182.679 207.841 183.752C207.578 183.871 207.311 183.99 207.042 184.11L206.774 184.229C206.595 184.308 206.416 184.386 206.228 184.463C206.049 184.541 205.863 184.619 205.677 184.695L205.119 184.925C203.814 185.462 202.477 185.974 201.173 186.479L200.615 186.696L200.064 186.912C199.697 187.055 199.335 187.198 198.979 187.341L198.448 187.555L197.926 187.768L197.67 187.876C197.499 187.947 197.332 188.018 197.165 188.089C193.328 189.736 190.567 191.411 191.147 193.489C191.163 193.548 191.181 193.604 191.201 193.659C191.253 193.813 191.324 193.958 191.413 194.095C191.465 194.176 191.525 194.253 191.592 194.323C192.274 195.032 193.515 194.92 195.08 194.357C195.3 194.276 195.519 194.192 195.736 194.104L195.872 194.048C196.23 193.896 196.609 193.726 196.996 193.542C197.093 193.496 197.191 193.452 197.289 193.401C199.203 192.465 201.372 191.205 203.524 190.058C204.385 189.593 205.258 189.152 206.142 188.733C208.18 187.774 210.096 187.094 211.636 187.094C212.359 187.094 212.997 187.242 213.529 187.582L213.618 187.641C213.952 187.876 214.232 188.178 214.441 188.528C214.482 188.595 214.522 188.666 214.561 188.739C215.322 190.184 214.685 191.68 213.194 193.147C211.763 194.556 209.537 195.937 207.007 197.215C206.819 197.31 206.631 197.405 206.44 197.498C198.91 201.196 189.049 203.981 188.912 204.016C186.284 204.697 182.526 205.591 178.292 206.26L177.666 206.358L177.563 206.373C177.089 206.445 176.614 206.512 176.138 206.574C175.655 206.639 175.167 206.698 174.676 206.753L174.586 206.763C172.806 206.968 171.019 207.104 169.228 207.169H169.202C168.554 207.192 167.907 207.204 167.259 207.204H166.512C165.524 207.191 164.538 207.146 163.553 207.07C163.53 207.07 163.505 207.07 163.482 207.064C163.129 207.037 162.777 207.004 162.425 206.965C162.06 206.926 161.696 206.882 161.333 206.833C161.094 206.801 160.856 206.765 160.618 206.726C160.376 206.687 160.134 206.647 159.893 206.605L159.564 206.543L159.539 206.538C159.192 206.472 158.847 206.399 158.503 206.319C158.303 206.274 158.104 206.23 157.907 206.176L157.788 206.146C157.69 206.122 157.595 206.096 157.498 206.07L157.445 206.056L157.137 205.966C157.025 205.935 156.913 205.901 156.801 205.868L156.762 205.857L156.471 205.768C156.361 205.734 156.251 205.698 156.142 205.662L155.874 205.573L155.677 205.504C155.487 205.437 155.298 205.368 155.111 205.296L154.933 205.226L154.786 205.168C154.502 205.054 154.22 204.935 153.941 204.81L153.756 204.72L153.725 204.706C153.659 204.675 153.594 204.644 153.528 204.617C153.399 204.555 153.271 204.491 153.144 204.426L153.105 204.407L152.921 204.31C152.594 204.139 152.274 203.957 151.96 203.764L151.788 203.658C151.702 203.605 151.616 203.55 151.532 203.494L151.308 203.346L151.067 203.18L150.923 203.077C150.771 202.969 150.622 202.857 150.476 202.742L150.243 202.563C150.15 202.488 150.058 202.412 149.967 202.335C149.89 202.272 149.815 202.206 149.74 202.14L149.734 202.135C149.653 202.064 149.574 201.993 149.495 201.92C149.417 201.849 149.339 201.777 149.263 201.704L149.254 201.695C149.174 201.619 149.096 201.542 149.019 201.463C148.942 201.385 148.863 201.307 148.788 201.227C148.713 201.148 148.636 201.067 148.562 200.984C148.488 200.902 148.42 200.827 148.35 200.746L148.327 200.719C148.259 200.641 148.192 200.562 148.126 200.481C147.983 200.31 147.844 200.135 147.71 199.956C147.575 199.776 147.443 199.592 147.314 199.405L147.191 199.221C147.027 198.981 146.867 198.739 146.712 198.493C146.596 198.316 146.483 198.138 146.373 197.957C146.302 197.844 146.234 197.73 146.166 197.618L146.138 197.572C146.073 197.462 146.009 197.354 145.947 197.245C145.911 197.186 145.877 197.127 145.845 197.066C145.812 197.004 145.774 196.941 145.739 196.878L145.682 196.779L145.647 196.715C145.58 196.595 145.514 196.474 145.45 196.352C145.42 196.298 145.391 196.244 145.36 196.192L145.271 196.019L145.181 195.848C144.956 195.398 144.743 194.942 144.543 194.48L144.472 194.311C144.426 194.198 144.383 194.086 144.337 193.975C144.315 193.921 144.293 193.868 144.274 193.814C144.167 193.537 144.067 193.257 143.975 192.975C143.942 192.874 143.91 192.775 143.88 192.675C143.808 192.448 143.743 192.219 143.685 191.988C143.614 191.719 143.551 191.448 143.498 191.175C143.487 191.12 143.476 191.065 143.467 191.012C143.415 190.745 143.373 190.476 143.34 190.206C143.332 190.153 143.326 190.1 143.32 190.047L143.303 189.885C143.281 189.673 143.264 189.46 143.254 189.247C143.254 189.193 143.249 189.139 143.247 189.087C143.242 188.981 143.24 188.875 143.239 188.769C143.183 184.496 145.345 180.388 149.968 175.767C158.203 167.54 162.997 155.501 162.997 155.501C162.997 155.501 163.126 154.996 163.394 154.269C163.431 154.168 163.47 154.064 163.514 153.955C163.67 153.548 163.846 153.148 164.041 152.758L164.08 152.683C164.246 152.351 164.428 152.027 164.624 151.712C164.67 151.639 164.714 151.567 164.765 151.494C164.912 151.277 165.067 151.065 165.23 150.86C165.319 150.749 165.416 150.639 165.513 150.532C165.552 150.49 165.59 150.448 165.631 150.408C166.108 149.915 166.653 149.513 167.27 149.299L167.348 149.273C167.4 149.256 167.452 149.24 167.505 149.225C167.566 149.209 167.627 149.195 167.69 149.182L167.719 149.176C167.849 149.15 167.981 149.133 168.114 149.124H168.125C168.194 149.124 168.264 149.117 168.335 149.117C168.424 149.117 168.507 149.117 168.594 149.126C168.684 149.134 168.773 149.144 168.863 149.158C169.605 149.276 170.311 149.718 170.919 150.4C171.15 150.66 171.358 150.94 171.54 151.236C171.66 151.428 171.773 151.631 171.88 151.845C171.923 151.934 171.964 152.016 172.004 152.104C172.108 152.33 172.202 152.56 172.284 152.795C172.479 153.345 172.626 153.911 172.723 154.487C172.807 154.992 172.857 155.502 172.873 156.013C172.881 156.286 172.881 156.563 172.873 156.842C172.819 158.14 172.553 159.421 172.086 160.634C172.044 160.745 171.997 160.857 171.952 160.969C171.86 161.195 171.759 161.417 171.65 161.634C171.569 161.799 171.484 161.965 171.392 162.13C171.332 162.24 171.269 162.35 171.206 162.46C171.045 162.734 170.871 163.006 170.684 163.277L170.571 163.439C170.129 164.055 169.637 164.633 169.099 165.167C168.569 165.698 168.001 166.189 167.4 166.637C166.798 167.083 166.233 167.577 165.711 168.114C164.208 169.691 163.858 171.083 164.196 172.138C164.25 172.304 164.321 172.465 164.407 172.617C164.508 172.791 164.628 172.951 164.764 173.097L164.817 173.152L164.871 173.206C164.925 173.258 164.982 173.309 165.043 173.359L165.103 173.407C165.248 173.519 165.402 173.619 165.563 173.707C165.61 173.732 165.652 173.757 165.705 173.781C165.879 173.866 166.058 173.939 166.242 173.998C166.293 174.015 166.344 174.03 166.396 174.046L166.461 174.063L166.551 174.087L166.628 174.106L166.712 174.124L166.795 174.141L166.874 174.154C166.932 174.164 166.992 174.174 167.052 174.181L167.109 174.19L167.213 174.2L167.277 174.207L167.382 174.214H167.444L167.554 174.22H167.9L167.999 174.214L168.113 174.207L168.252 174.194L168.382 174.179C168.412 174.179 168.442 174.171 168.472 174.165C168.872 174.107 169.264 174.001 169.639 173.849L169.798 173.782C169.887 173.743 169.977 173.702 170.059 173.658C170.235 173.57 170.406 173.47 170.57 173.361C170.799 173.211 171.015 173.043 171.217 172.858C171.265 172.815 171.312 172.769 171.358 172.725C171.381 172.703 171.403 172.682 171.425 172.658C171.469 172.613 171.514 172.569 171.558 172.52C171.878 172.168 172.155 171.78 172.383 171.363C174.34 167.804 176.391 164.298 178.534 160.849L178.828 160.378L179.125 159.907C179.273 159.668 179.423 159.433 179.572 159.199L179.722 158.965C180.22 158.185 180.726 157.41 181.241 156.641L181.546 156.185C182.158 155.278 182.768 154.396 183.373 153.558L183.674 153.143C184.332 152.236 185.017 151.348 185.728 150.482L186.01 150.144C186.057 150.088 186.1 150.032 186.151 149.978C186.244 149.868 186.337 149.761 186.428 149.657C186.474 149.604 186.517 149.552 186.566 149.5L186.834 149.198L186.968 149.051C187.103 148.906 187.235 148.767 187.365 148.634C187.455 148.544 187.538 148.455 187.624 148.371C188.131 147.853 188.69 147.388 189.293 146.985L189.433 146.895C189.567 146.805 189.706 146.721 189.848 146.645C192.212 145.303 194.169 145.204 195.296 146.331C195.978 147.013 196.356 148.144 196.335 149.718C196.335 149.787 196.335 149.857 196.33 149.929V150.006C196.33 150.078 196.324 150.15 196.318 150.223C196.318 150.313 196.308 150.402 196.299 150.492C196.29 150.581 196.285 150.649 196.276 150.729C196.276 150.751 196.272 150.774 196.268 150.798C196.262 150.867 196.253 150.938 196.243 151.009C196.243 151.03 196.243 151.052 196.235 151.074C196.224 151.169 196.21 151.263 196.194 151.357C196.183 151.447 196.168 151.531 196.152 151.619L196.126 151.768C196.1 151.91 196.067 152.05 196.026 152.188C195.948 152.447 195.854 152.7 195.743 152.946C195.588 153.284 195.417 153.613 195.229 153.933C195.125 154.111 195.018 154.286 194.907 154.459C194.793 154.638 194.673 154.819 194.549 155.002C194.233 155.454 193.905 155.897 193.564 156.33L193.408 156.527C192.852 157.22 192.278 157.899 191.686 158.562L191.499 158.772C191.247 159.053 190.991 159.336 190.729 159.62L190.532 159.834C190.401 159.977 190.264 160.12 190.132 160.264C190.001 160.407 189.864 160.552 189.726 160.697L189.315 161.13L188.898 161.566L188.478 162.002C188.196 162.294 187.913 162.586 187.628 162.878C183.573 167.037 179.301 171.182 177.855 173.766C177.758 173.934 177.671 174.108 177.593 174.285C177.387 174.755 177.301 175.157 177.36 175.482C177.379 175.589 177.416 175.691 177.471 175.785C177.552 175.926 177.651 176.056 177.766 176.172C177.819 176.224 177.875 176.272 177.934 176.316C178.232 176.528 178.591 176.637 178.957 176.627H179.071L179.188 176.618L179.305 176.605L179.402 176.591C179.415 176.589 179.429 176.587 179.442 176.583L179.531 176.566L179.554 176.561L179.653 176.54L179.688 176.531C179.723 176.522 179.757 176.513 179.792 176.503C179.827 176.493 179.875 176.48 179.917 176.466C180.093 176.413 180.265 176.35 180.434 176.278C180.523 176.242 180.61 176.203 180.696 176.161C180.741 176.141 180.786 176.12 180.828 176.098L180.962 176.032C181.282 175.866 181.594 175.685 181.898 175.491L182.031 175.401C182.076 175.373 182.121 175.344 182.164 175.312L182.297 175.223L182.368 175.174L182.56 175.039C182.739 174.916 182.906 174.789 183.075 174.66L183.09 174.648L183.359 174.44C183.726 174.15 184.074 173.858 184.39 173.583L184.6 173.399L184.619 173.381L184.729 173.284C184.987 173.052 185.217 172.836 185.408 172.658L185.487 172.581C185.556 172.516 185.619 172.455 185.676 172.403L185.788 172.292L185.828 172.253L185.839 172.242L185.956 172.125L186.03 172.048L186.039 172.041L186.074 172.009L186.118 171.969L186.132 171.956L186.169 171.922L186.373 171.743L186.487 171.641C186.548 171.588 186.607 171.534 186.666 171.479L186.802 171.358C186.827 171.338 186.851 171.316 186.876 171.294L187.019 171.169L187.229 170.984L187.341 170.887C187.776 170.509 188.305 170.052 188.913 169.537L189.162 169.326L189.573 168.981L189.994 168.63C190.544 168.173 191.136 167.688 191.762 167.185L192.173 166.855C192.523 166.576 192.882 166.292 193.246 166.006C193.393 165.891 193.542 165.776 193.694 165.662C194.066 165.373 194.44 165.086 194.817 164.803C195.675 164.155 196.56 163.506 197.456 162.874L197.84 162.606C198.109 162.421 198.377 162.235 198.645 162.054L198.888 161.89C199.367 161.565 199.853 161.248 200.343 160.939L200.586 160.786L200.827 160.636C201.069 160.486 201.309 160.339 201.548 160.196L201.787 160.053L202.265 159.775L202.734 159.506L202.829 159.454L203.2 159.25C203.355 159.166 203.509 159.085 203.663 159.006L203.892 158.888L204.115 158.776C204.193 158.739 204.27 158.7 204.346 158.663C204.848 158.415 205.36 158.187 205.88 157.979C206.021 157.919 206.161 157.865 206.3 157.818L206.71 157.674C206.833 157.633 206.953 157.594 207.068 157.559L207.108 157.547C207.17 157.527 207.232 157.509 207.293 157.493L207.311 157.488C207.439 157.451 207.566 157.419 207.691 157.389H207.7C208.054 157.304 208.414 157.243 208.777 157.206C208.944 157.189 209.111 157.18 209.279 157.181H209.363C209.475 157.181 209.583 157.188 209.69 157.199C209.739 157.199 209.788 157.209 209.836 157.215H209.856C209.904 157.221 209.952 157.228 210 157.239C210.047 157.248 210.095 157.256 210.141 157.267H210.156C210.203 157.277 210.245 157.289 210.294 157.303C210.548 157.374 210.79 157.484 211.012 157.628C211.121 157.699 211.223 157.779 211.317 157.868L211.344 157.894C211.362 157.91 211.379 157.927 211.395 157.944L211.444 157.997C211.846 158.418 212.178 158.901 212.428 159.427L212.466 159.517C212.551 159.717 212.618 159.924 212.666 160.135C212.808 160.781 212.753 161.455 212.508 162.07C212.415 162.318 212.302 162.557 212.169 162.785C211.858 163.309 211.489 163.796 211.07 164.237L210.981 164.332C210.848 164.472 210.71 164.612 210.565 164.752C210.501 164.815 210.434 164.877 210.367 164.94L210.162 165.129L210.055 165.224C209.797 165.454 209.532 165.677 209.263 165.893C209.1 166.025 208.936 166.154 208.77 166.281C208.184 166.729 207.587 167.161 206.979 167.578C206.612 167.83 206.242 168.077 205.869 168.321C204.95 168.924 204.021 169.512 203.083 170.084C201.115 171.294 198.934 172.588 196.609 173.995L196.007 174.36C195.348 174.762 194.726 175.146 194.14 175.512L193.845 175.697L193.287 176.055C192.917 176.292 192.548 176.531 192.179 176.77L191.882 176.966C191.737 177.06 191.593 177.156 191.449 177.252L191.308 177.342L190.876 177.633L190.647 177.79L190.379 177.976L190.13 178.149C189.713 178.444 189.325 178.725 188.968 178.992L188.834 179.094C188.624 179.253 188.416 179.415 188.211 179.58C187.902 179.829 187.62 180.067 187.367 180.296L187.243 180.409C187.172 180.474 187.102 180.539 187.035 180.603C186.989 180.648 186.946 180.693 186.898 180.736L186.834 180.8C186.691 180.944 186.551 181.091 186.416 181.242L186.35 181.318C186.203 181.488 186.075 181.651 185.963 181.81L185.913 181.881C185.825 182.009 185.744 182.141 185.671 182.277C185.652 182.311 185.635 182.345 185.618 182.379L185.569 182.481L185.536 182.555L185.515 182.605L185.498 182.65L185.475 182.711C185.413 182.88 185.37 183.056 185.345 183.234L185.337 183.296L185.331 183.354V183.669C185.331 183.695 185.331 183.721 185.338 183.749L185.343 183.797C185.343 183.823 185.349 183.848 185.353 183.876C185.357 183.902 185.364 183.949 185.372 183.986V183.991C185.379 184.026 185.386 184.06 185.395 184.095C185.404 184.13 185.413 184.17 185.424 184.206C185.443 184.277 185.467 184.347 185.492 184.417C185.508 184.459 185.523 184.5 185.54 184.541C185.54 184.549 185.546 184.558 185.55 184.566L185.586 184.647L185.636 184.758C185.69 184.873 185.749 184.985 185.813 185.094L185.879 185.208L185.947 185.322C185.959 185.341 185.973 185.359 185.988 185.376L186.01 185.399L186.035 185.422L186.061 185.442C186.099 185.469 186.14 185.49 186.183 185.505C186.206 185.513 186.23 185.519 186.254 185.525C186.831 185.655 188.017 185.178 189.593 184.346C189.682 184.298 189.78 184.248 189.875 184.196L190.355 183.934L190.589 183.804C190.756 183.715 190.926 183.614 191.1 183.515L191.417 183.336C193.5 182.137 195.988 180.597 198.56 179.093C198.801 178.952 199.043 178.811 199.285 178.672L199.771 178.361C200.335 178.038 200.902 177.719 201.471 177.404C202.188 177.01 202.91 176.626 203.639 176.254L204.115 176.013C204.431 175.857 204.744 175.705 205.053 175.557C205.651 175.273 206.256 175.003 206.868 174.748L207.203 174.612L207.243 174.596C209.018 173.893 210.627 173.459 211.929 173.459C212.21 173.456 212.492 173.48 212.769 173.528H212.778C212.867 173.544 212.948 173.562 213.031 173.582H213.046C213.259 173.636 213.466 173.713 213.662 173.812C213.937 173.954 214.184 174.143 214.393 174.371C214.489 174.477 214.574 174.592 214.649 174.714C214.789 174.929 214.899 175.162 214.978 175.406C215.01 175.501 215.038 175.594 215.067 175.693C215.278 176.45 215.257 177.253 215.007 177.998Z" fill="#FF9D00"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M203.21 123.685V123.194C203.21 81.34 169.292 47.411 127.435 47.411C85.5791 47.411 51.648 81.342 51.648 123.194V123.358C51.646 123.467 51.645 123.576 51.648 123.685C51.6529 123.848 51.6546 124.011 51.653 124.174L51.6581 124.534L51.661 124.663C51.661 124.723 51.6631 124.782 51.6651 124.842C51.6681 124.937 51.67 125.033 51.67 125.128L51.681 125.517L51.697 125.974L51.702 126.124L51.722 126.597V126.62C51.73 126.805 51.7401 126.989 51.7491 127.173L51.75 127.187C51.76 127.375 51.7701 127.564 51.7821 127.753C51.7921 127.927 51.802 128.101 51.815 128.275L51.8171 128.306C51.8258 128.455 51.8358 128.605 51.847 128.754L51.85 128.794L51.883 129.226L51.8861 129.254C51.8921 129.338 51.898 129.422 51.906 129.503C51.9658 130.224 52.0355 130.945 52.1151 131.664L52.12 131.709L52.181 132.238L52.2491 132.793L52.299 133.17L52.322 133.347C52.3753 133.755 52.433 134.162 52.495 134.568L52.4991 134.595L52.558 134.979C52.8435 136.808 53.1971 138.626 53.618 140.429L53.6231 140.451L53.655 140.586L53.746 140.971L53.802 140.904C56.002 138.274 59.158 136.824 62.689 136.824C65.519 136.824 68.4221 137.76 71.3321 139.605C73.2621 140.831 75.3961 143.002 77.5921 145.733C79.6241 142.911 82.4721 141.035 85.7301 140.523C86.3513 140.425 86.9792 140.376 87.6081 140.375C95.0441 140.375 99.523 146.828 101.215 152.633C102.051 154.594 106.08 163.526 112.156 169.568C121.392 178.795 123.703 188.316 119.132 198.511H119.148C119.459 198.546 119.772 198.578 120.087 198.607C120.274 198.625 120.46 198.643 120.648 198.659L120.714 198.665L121.127 198.7L121.507 198.73C121.869 198.758 122.232 198.784 122.596 198.807L122.885 198.824L123.114 198.838L123.256 198.846L123.703 198.869L123.825 198.874L124.294 198.895L124.816 198.915L125.235 198.927L125.305 198.929C125.394 198.933 125.483 198.936 125.572 198.936L125.668 198.939C126.258 198.953 126.847 198.96 127.437 198.959H128.063L128.51 198.954C128.62 198.949 128.729 198.949 128.84 198.949H129.014L129.165 198.945C129.224 198.943 129.283 198.941 129.343 198.941H129.522L129.873 198.932L130.401 198.914L130.982 198.888C131.15 198.882 131.316 198.873 131.482 198.865L131.661 198.854L131.927 198.84L132.083 198.831L132.201 198.823L132.738 198.788L133.274 198.749L133.761 198.71L134.103 198.681L134.479 198.647C135.107 198.591 135.733 198.525 136.359 198.45L136.786 198.399C132.287 188.247 134.616 178.767 143.813 169.577C149.876 163.519 153.905 154.587 154.745 152.625C156.438 146.821 160.914 140.368 168.352 140.368C168.981 140.368 169.61 140.418 170.231 140.516C173.486 141.028 176.334 142.904 178.369 145.726C180.566 142.996 182.699 140.823 184.63 139.597C187.539 137.753 190.445 136.817 193.272 136.817C196.388 136.817 199.212 137.947 201.345 140.02C201.384 139.851 201.422 139.682 201.459 139.512L201.568 139.006C201.607 138.821 201.646 138.636 201.683 138.451C201.749 138.124 201.815 137.797 201.878 137.467C201.944 137.125 202.007 136.781 202.067 136.437L202.098 136.251C202.117 136.141 202.135 136.031 202.156 135.92C202.19 135.748 202.218 135.576 202.246 135.402L202.257 135.336L202.328 134.883L202.398 134.424V134.42C202.449 134.081 202.497 133.742 202.542 133.403L202.553 133.319L202.616 132.841L202.667 132.433L202.757 131.629L202.792 131.306L202.801 131.218C202.82 131.044 202.838 130.87 202.854 130.696V130.682C202.867 130.544 202.881 130.405 202.893 130.266C202.964 129.478 203.024 128.686 203.072 127.891C203.081 127.761 203.088 127.63 203.096 127.499V127.493L203.122 127.002L203.128 126.892C203.144 126.56 203.158 126.228 203.169 125.896V125.884L203.174 125.754C203.179 125.645 203.183 125.535 203.183 125.425L203.185 125.381C203.189 125.278 203.193 125.172 203.193 125.067L203.196 124.977C203.199 124.872 203.202 124.768 203.202 124.663L203.204 124.574C203.207 124.441 203.21 124.307 203.21 124.174V123.685ZM108.638 199.391C114.64 190.59 114.214 183.984 105.98 175.754C97.7441 167.523 92.951 155.487 92.951 155.487C92.951 155.487 91.1621 148.496 87.0821 149.138C83.0021 149.78 80.0091 160.227 88.5521 166.622C97.0941 173.017 86.8521 177.353 83.5641 171.352C80.2761 165.35 71.299 149.923 66.645 146.972C61.991 144.021 58.718 145.675 59.815 151.757C60.36 154.776 65.4281 159.929 70.1631 164.743C74.9671 169.627 79.428 174.163 78.474 175.768C76.581 178.955 69.9141 172.023 69.9141 172.023C69.9141 172.023 49.038 153.025 44.494 157.976C40.304 162.539 46.765 166.418 56.7211 172.397C57.5671 172.905 58.4391 173.429 59.3321 173.969C70.7231 180.865 71.609 182.684 69.992 185.293C69.395 186.257 65.582 183.968 60.892 181.153C52.897 176.352 42.3551 170.023 40.8661 175.688C39.5781 180.591 47.334 183.595 54.368 186.32C60.228 188.59 65.5881 190.666 64.7991 193.484C63.9821 196.406 59.5531 193.969 54.7121 191.305C49.2771 188.314 43.3221 185.038 41.3731 188.735C37.6901 195.725 66.7831 203.954 67.0231 204.015C76.4231 206.453 100.295 211.619 108.638 199.391ZM147.303 199.391C141.301 190.59 141.727 183.984 149.962 175.754C158.197 167.523 162.99 155.487 162.99 155.487C162.99 155.487 164.779 148.496 168.859 149.138C172.939 149.78 175.932 160.227 167.39 166.622C158.847 173.017 169.089 177.353 172.377 171.352C175.666 165.35 184.637 149.923 189.291 146.972C193.945 144.021 197.22 145.675 196.122 151.757C195.578 154.776 190.509 159.929 185.774 164.744C180.97 169.628 176.509 174.163 177.462 175.768C179.355 178.955 186.027 172.019 186.027 172.019C186.027 172.019 206.902 153.022 211.448 157.973C215.637 162.535 209.176 166.415 199.219 172.394C198.348 172.917 197.478 173.441 196.609 173.966C185.218 180.862 184.332 182.681 185.948 185.289C186.546 186.254 190.359 183.964 195.048 181.149C203.044 176.349 213.586 170.019 215.075 175.685C216.364 180.588 208.607 183.592 201.573 186.317C195.713 188.587 190.353 190.663 191.141 193.481C191.957 196.402 196.385 193.965 201.225 191.301C206.66 188.31 212.616 185.032 214.564 188.732C218.248 195.726 189.15 203.947 188.915 204.007C179.515 206.453 155.643 211.619 147.303 199.391Z" fill="#FFD21E"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M152.047 102.567C153.229 102.985 154.108 104.257 154.944 105.468C156.074 107.104 157.126 108.627 158.74 107.769C160.644 106.756 162.205 105.202 163.225 103.302C164.246 101.402 164.681 99.2427 164.475 97.096C164.321 95.4908 163.813 93.9398 162.987 92.5548C162.161 91.1697 161.038 89.985 159.7 89.0862C158.361 88.1874 156.839 87.5968 155.245 87.3569C153.65 87.117 152.022 87.2339 150.478 87.699C148.934 88.1639 147.513 88.9653 146.316 90.0455C145.119 91.1257 144.176 92.4578 143.556 93.946C142.936 95.4342 142.653 97.0415 142.728 98.652C142.804 100.263 143.235 101.836 143.992 103.26C144.74 104.667 146.4 104.003 148.152 103.302C149.525 102.753 150.956 102.181 152.047 102.567ZM100.672 102.567C99.49 102.985 98.611 104.258 97.775 105.468C96.645 107.105 95.592 108.627 93.979 107.769C91.5845 106.501 89.7482 104.386 88.8278 101.838C87.9075 99.2895 87.9692 96.4896 89.0008 93.9841C90.0324 91.4786 91.9601 89.4471 94.408 88.2855C96.856 87.1239 99.6488 86.9156 102.242 87.701C104.307 88.3228 106.141 89.5427 107.513 91.2065C108.885 92.8704 109.732 94.9035 109.949 97.049C110.165 99.1945 109.74 101.356 108.728 103.26C107.979 104.667 106.319 104.003 104.567 103.303C103.193 102.753 101.764 102.181 100.672 102.567ZM144.099 149.318C152.242 142.903 155.233 132.429 155.233 125.977C155.233 120.877 151.802 122.482 146.309 125.202L145.999 125.355C140.957 127.852 134.245 131.177 126.877 131.177C119.508 131.177 112.796 127.852 107.755 125.354C102.084 122.545 98.527 120.783 98.527 125.978C98.527 132.634 101.709 143.563 110.443 149.912C111.596 147.573 113.219 145.497 115.211 143.813C117.202 142.129 119.52 140.874 122.018 140.126C122.89 139.866 123.788 141.367 124.707 142.904C125.594 144.386 126.501 145.902 127.423 145.902C128.406 145.902 129.371 144.408 130.314 142.95C131.299 141.425 132.26 139.94 133.189 140.237C137.864 141.738 141.775 144.993 144.099 149.318Z" fill="#32343D"/>
<path d="M144.097 149.317C139.856 152.659 134.219 154.9 126.878 154.9C119.981 154.9 114.587 152.922 110.443 149.911C111.596 147.572 113.219 145.495 115.211 143.812C117.202 142.128 119.52 140.873 122.018 140.125C123.73 139.614 125.545 145.901 127.423 145.901C129.433 145.901 131.37 139.655 133.189 140.236C137.863 141.738 141.773 144.993 144.097 149.317Z" fill="#FF323D"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M81.2 111.64C80.2312 112.288 79.1173 112.687 77.9572 112.801C76.7971 112.916 75.6267 112.742 74.55 112.295C73.6893 111.94 72.9072 111.418 72.2488 110.759C71.5903 110.101 71.0684 109.319 70.713 108.458C70.267 107.381 70.0935 106.211 70.2082 105.051C70.3228 103.891 70.7219 102.777 71.37 101.808C72.1488 100.642 73.2558 99.7333 74.5512 99.1967C75.8466 98.6601 77.272 98.5197 78.6471 98.7935C80.0223 99.0672 81.2853 99.7427 82.2764 100.734C83.2675 101.726 83.9422 102.99 84.215 104.365C84.4883 105.74 84.3477 107.165 83.8113 108.46C83.2748 109.755 82.3654 110.861 81.2 111.64ZM182.613 111.64C181.644 112.288 180.53 112.687 179.37 112.801C178.209 112.916 177.039 112.742 175.962 112.295C175.101 111.939 174.319 111.418 173.661 110.759C173.003 110.101 172.481 109.319 172.125 108.458C171.68 107.381 171.507 106.211 171.621 105.051C171.736 103.891 172.135 102.777 172.782 101.808C173.364 100.936 174.133 100.205 175.032 99.6658C175.931 99.1269 176.938 98.7942 177.981 98.6917C179.025 98.5891 180.078 98.7193 181.064 99.0728C182.051 99.4264 182.947 99.9944 183.688 100.736C184.68 101.727 185.355 102.99 185.628 104.365C185.902 105.74 185.761 107.165 185.224 108.46C184.687 109.755 183.779 110.861 182.613 111.64Z" fill="#FFAD03"/>
</svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>